\documentclass{iuphd_proposal}
\usepackage[utf8]{inputenc}
\usepackage{cite}

% exta packages
\usepackage{graphicx, caption, subfig, setspace, soul, color, paralist}
% \usepackage{subcaption}

\usepackage{rotating}
\usepackage{relsize}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{array}
\usetikzlibrary{arrows,shapes}

% extra commands
%\captionsetup[figure]{font={stretch=1.1}}
\newcommand{\fixme}[1]{\sethlcolor{yellow}\hl{#1}}
\newcommand{\xhdr}[1]{\vspace{4pt}\noindent {\textit{\textbf{#1.}}}}
%\newcommand{\rebuttal}[1]{\textcolor{red}{#1}}
\newcommand{\rebuttal}[1]{#1}


%data for Title Page
\title{Web-scale Visual Content Mining with Computer Vision Methods}
\author{}
\date{}

%data for Acceptance Page
\committeechair{}
\readertwo{}
\readerthree{}
\readerfour{}
\defensedate{}


%data for Copyright Page
\cryear{}

\begin{document}
\maketitle

% \acceptancepage

% \copyrightpage

%\begin{dedication}
%\end{dedication}

% \begin{acknowledgments}
% \end{acknowledgments}

%\begin{preface}
%\end{preface}

\begin{abstract}
Social media provides low-cost and easy access to a large number of images with a wide variety of visual content. With this new source of large-scale image data, there is a critical demand for novel, scalable methods that can understand the information behind the visual content. For example, photos shared on social media are usually accompanied with temporal and location metadata, user profiles and textual annotations. When we integrate the visual content by user profiles or location tags, we can estimate a large variety of information. For example, we can help research in Psychology when we are interested in the human beings who take these photos and in Ecology when we are interested in the natural scenes as the visual content. 
These attractive properties of this new data source also bring us new challenges.
Being able to efficiently processing data with advanced computer vision techniques is an important requirement.
To accommodate the graphical structure of metadata in social media, we also need to develop new models and systems.

This thesis introduces three projects: a cloud based robotic system testing the feasibility of a memory and computing consuming task to work in near real time; a data mining application supporting Psychology research in gender differences in preference of color; and a natural event tracking system on a continental scale.
We design and implement a cloud based system to apply these algorithms for object detection and recognition with the best precision in near real time. We test our method on an aerial autonomous vehicle.
We take advantage of this new data source for psychology research. Based on the color pixels of these photos, we analyze the gender difference in color preference. We study the distribution of color pixels with respect to genders of photographers across geographic locations and content. We find strong sex differences for the predominant reddish and bluish hues, with female users uploading more photographs containing more reddish pixels and male users uploading more photographs containing more bluish pixels.  Furthermore, we take Google Street View to represent the color distribution in the environment, and compare with Flickr photos in three popular outdoor locations. We observe the overall preference of saturated color and reddish color of human compared to the environment.
By mining visual content on social media websites web-scale images further benefit studies about the state of nature. We develop and evaluate three models to study ecology phenomena such as snow and vegetation coverage.
First, we learn a binomial distribution to model the probability of the appearance of a natural phenomenon. 
Then, we compute the histogram of the confidence of each image being a positive evidence. Based on this histogram, we learn a classification model for the confidence of each user, and similarly apply this method to predict for each time and location.
Finally, inspired by the study of multiple instance learning, we propose an end to end system taking a sequence of images as input and giving predictions as the final output of this holistic system. This process will happen twice, once for users and once for each day and location. The two aggregating processes are optimized simultaneously.

\end{abstract}

\tableofcontents

\chapter{Introduction}
\input{intro}

\chapter{Real-time, Cloud-based Ojbect Detection for Unmanned Aerial Vehicles}
\input{chapter2}

\chapter{Assessing color preferences and sex differences using massive online data}
\input{chapter3}

% \chapter{Detecting Hands based on Visual Appearance}
% Bla Bla Bla
% 
% \chapter{Using Hands to Infer Social Activities}
% Bla Bla Bla
% 
% \chapter{Conclusion}
% \input{conclusion}
% 
% \chapter{Dissertation Timeline}
% \input{timeline}
% 
% \chapter*{Curriculum Vitae}
% \input{cv}


\bibliographystyle{plain}
\bibliography{proposal}

%\include{CV}
\end{document}
