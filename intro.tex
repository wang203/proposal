Social media encourages the development of online social network, connecting billions of users sharing status and comments in text and multimedia format.
These increasingly large number of multimedia files such as photographs become a new crowd sourcing data with high variety and publiclly available.
Along with the image files and text annotations, social networking websites and mobile applications also record user profiles as well as time and location metadata of users activity.
This new data source is quite noisy but is also easy accessible. 
It collects data constantly from a broad selection of locations on this earth. 
To better understand the information behind this large collction of data, there is a critical demand for novel, scalable methods to navigate the visual content together with the textual annotation and user activity.
Researchers from computer vision, multimedia, data mining and machine learning become more and more interested in this interdisplinery area, especially with the progress in computer vision and with the development of computing compacity.

When we integrate the visual content by the metadata of user activities, we will provide a very low-cost, large scale data source for researchers in many areas of social and natural science.
For example, we will help research in Psycology when we are interested in the human behavior of those who take photos and share on social media, we will use this new data source to help research
